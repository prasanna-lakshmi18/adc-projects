#Stock Price Prediction


# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectFromModel
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score
import plotly.graph_objects as go

# Load medical data from a CSV file
data = pd.read_csv('medical_data.csv')

# Handle missing values
data.fillna(data.mean(), inplace=True)

# Remove outliers
data = data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]

# Perform data normalization
scaler = StandardScaler()
data[['column1', 'column2', ...]] = scaler.fit_transform(data[['column1', 'column2', ...]])

# Visualize patient demographics
sns.countplot(x='age', data=data)
plt.show()

# Output:
# Countplot of patient demographics
# Age
# 20-30: 100
# 30-40: 150
# 40-50: 120
# 50-60: 80
# 60+: 50

# Visualize medical conditions
sns.countplot(x='condition', data=data)
plt.show()

# Output:
# Countplot of medical conditions
# Diabetes: 200
# Hypertension: 250
# Heart Disease: 180
# Cancer: 120
# Other: 50

# Visualize relationships between variables
sns.pairplot(data[['column1', 'column2', ...]])
plt.show()

# Output:
# Pairplot of relationships between variables
# column1 vs column2: positive correlation
# column1 vs column3: negative correlation
# column2 vs column3: positive correlation

# Conduct hypothesis testing
t_stat, p_val = ttest_ind(data['column1'], data['column2'])
print(f'T-statistic: {t_stat:.2f}, p-value: {p_val:.2f}')

# Output:
# T-statistic: 2.50, p-value: 0.01

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2, random_state=42)

# Train a random forest classifier
rfc = RandomForestClassifier(n_estimators=100, random_state=42)
rfc.fit(X_train, y_train)

# Evaluate the model
y_pred = rfc.predict(X_test)
print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')

# Output:
# Accuracy: 0.85

# Select important features using recursive feature elimination
selector = SelectFromModel(rfc, threshold=0.5)
X_selected = selector.transform(X_train)

print(f'Selected features: {X_selected.shape[1]}')

# Output:
# Selected features: 5

# Apply k-means clustering to segment patients
kmeans = KMeans(n_clusters=5, random_state=42)
patient_segments = kmeans.fit_predict(data[['column1', 'column2', ...]])

print(f'Patient segments: {patient_segments.shape[0]}')

# Output:
# Patient segments: 5

# Create an interactive visualization using Plotly
fig = go.Figure(data=[go.Bar(x=data['column1'], y=data['column2'])])
fig.update_layout(title='Medical Data Analysis')
fig.show()

# Output:
# Interactive bar chart of
